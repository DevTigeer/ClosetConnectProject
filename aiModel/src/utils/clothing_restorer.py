# clothing_restorer.py (ë¯¸ì‚¬ìš© - Stable Diffusion Inpainting) ðŸŽ¨
# í˜„ìž¬ëŠ” Google AI Imagenì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ íŒŒì¼ì€ ë¯¸ì‚¬ìš©

from diffusers import StableDiffusionInpaintPipeline
from PIL import Image, ImageDraw
import torch
import numpy as np
from pathlib import Path

class ClothingRestorer:
    """Stable Diffusion Inpaintingì„ ì‚¬ìš©í•œ ì˜ìƒ ë³µì›"""
    
    def __init__(self, model_id="runwayml/stable-diffusion-inpainting"):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_id: Hugging Face ëª¨ë¸ ID
        """
        print("ðŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if torch.cuda.is_available():
            self.device = "cuda"
            self.dtype = torch.float16
        elif torch.backends.mps.is_available():
            self.device = "mps"
            self.dtype = torch.float32  # MPSëŠ” float32 ì‚¬ìš©
        else:
            self.device = "cpu"
            self.dtype = torch.float32
        
        print(f"ðŸ“± Device: {self.device}")
        
        # íŒŒì´í”„ë¼ì¸ ë¡œë“œ
        self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
            model_id,
            torch_dtype=self.dtype,
            safety_checker=None  # ì•ˆì „ì„± ì²´ì»¤ ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)
        )
        self.pipe = self.pipe.to(self.device)
        
        # ë©”ëª¨ë¦¬ ìµœì í™” (ì„ íƒ)
        if self.device == "cuda":
            self.pipe.enable_attention_slicing()
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    
    def prepare_image_and_mask(self, image_path, extend_ratio=0.5):
        """
        ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ì¤€ë¹„
        
        Args:
            image_path: ìž…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            extend_ratio: í™•ìž¥ ë¹„ìœ¨ (0.5 = 50% í™•ìž¥)
        
        Returns:
            extended_image: í™•ìž¥ëœ ì´ë¯¸ì§€
            mask: ì±„ì›Œì•¼ í•  ì˜ì—­ ë§ˆìŠ¤í¬
        """
        print(f"ðŸ“‚ ì´ë¯¸ì§€ ë¡œë“œ: {image_path}")
        
        # 1. ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        original = Image.open(image_path).convert("RGB")
        orig_width, orig_height = original.size
        
        print(f"ðŸ“ ì›ë³¸ í¬ê¸°: {orig_width}x{orig_height}")
        
        # 2. í™•ìž¥í•  í¬ê¸° ê³„ì‚°
        extend_pixels_height = int(orig_height * extend_ratio)
        extend_pixels_width = int(orig_width * 0.2)  # ì¢Œìš°ëŠ” 20%ë§Œ
        
        new_width = orig_width + (extend_pixels_width * 2)
        new_height = orig_height + (extend_pixels_height * 2)
        
        # 512ì˜ ë°°ìˆ˜ë¡œ ì¡°ì • (Stable Diffusion ìµœì í™”)
        new_width = ((new_width + 63) // 64) * 64
        new_height = ((new_height + 63) // 64) * 64
        
        print(f"ðŸ“ í™•ìž¥ í¬ê¸°: {new_width}x{new_height}")
        
        # 3. í°ìƒ‰ ìº”ë²„ìŠ¤ ìƒì„±
        extended_image = Image.new("RGB", (new_width, new_height), (255, 255, 255))
        
        # 4. ì›ë³¸ ì´ë¯¸ì§€ ì¤‘ì•™ ë°°ì¹˜
        paste_x = (new_width - orig_width) // 2
        paste_y = (new_height - orig_height) // 2
        extended_image.paste(original, (paste_x, paste_y))
        
        # 5. ë§ˆìŠ¤í¬ ìƒì„± (ì±„ì›Œì•¼ í•  ì˜ì—­ = í°ìƒ‰)
        mask = Image.new("L", (new_width, new_height), 255)  # ì „ì²´ í°ìƒ‰
        mask_draw = ImageDraw.Draw(mask)
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì˜ì—­ì€ ê²€ì€ìƒ‰ (ë³€ê²½í•˜ì§€ ì•ŠìŒ)
        mask_draw.rectangle(
            [paste_x, paste_y, paste_x + orig_width, paste_y + orig_height],
            fill=0
        )
        
        return extended_image, mask
    
    def detect_clothing_type(self, image_path):
        """
        ì˜ìƒ íƒ€ìž… ìžë™ ê°ì§€
        
        Returns:
            str: 'top', 'bottom', 'dress'
        """
        image = Image.open(image_path)
        width, height = image.size
        ratio = height / width
        
        if ratio > 1.5:
            return "bottom"  # ë°”ì§€/ì¹˜ë§ˆ (ì„¸ë¡œë¡œ ê¹€)
        elif ratio < 0.8:
            return "top"     # ìƒì˜ (ê°€ë¡œë¡œ ë„“ìŒ)
        else:
            return "dress"   # ì›í”¼ìŠ¤
    
    def get_prompt_for_clothing(self, clothing_type, filename=""):
        """
        ì˜ìƒ íƒ€ìž…ì— ë§žëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            clothing_type: ì˜ìƒ íƒ€ìž…
            filename: íŒŒì¼ëª… (ì¶”ê°€ ížŒíŠ¸)
        
        Returns:
            tuple: (prompt, negative_prompt)
        """
        # íŒŒì¼ëª…ì—ì„œ ížŒíŠ¸ ì¶”ì¶œ
        filename_lower = filename.lower()
        
        base_prompt = "professional product photography, high quality, detailed, "
        negative_prompt = "blurry, low quality, distorted, deformed, "
        
        if "skirt" in filename_lower or clothing_type == "bottom":
            prompt = base_prompt + "complete full-length skirt, flowing fabric, elegant design, white background"
            negative = negative_prompt + "incomplete, cropped, person, body parts"
        
        elif "pants" in filename_lower or "ë°”ì§€" in filename:
            prompt = base_prompt + "complete full-length pants, trousers, smooth fabric, white background"
            negative = negative_prompt + "incomplete, cropped, person, legs"
        
        elif "dress" in filename_lower or "ì›í”¼ìŠ¤" in filename:
            prompt = base_prompt + "complete full-length dress, flowing fabric, elegant, white background"
            negative = negative_prompt + "incomplete, cropped, person, body"
        
        elif "ìƒì˜" in filename or clothing_type == "top":
            prompt = base_prompt + "complete shirt, blouse, top garment, smooth fabric, white background"
            negative = negative_prompt + "incomplete, cropped, person, arms"
        
        else:
            prompt = base_prompt + "complete clothing item, professional product photo, white background"
            negative = negative_prompt + "incomplete, cropped, person, body parts"
        
        return prompt, negative
    
    def restore(
        self,
        image_path,
        output_path=None,
        extend_ratio=0.5,
        num_inference_steps=50,
        guidance_scale=7.5,
        strength=0.8
    ):
        """
        ì´ë¯¸ì§€ ë³µì› ìˆ˜í–‰
        
        Args:
            image_path: ìž…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            output_path: ì¶œë ¥ ê²½ë¡œ (Noneì´ë©´ ìžë™ ìƒì„±)
            extend_ratio: í™•ìž¥ ë¹„ìœ¨
            num_inference_steps: ì¶”ë¡  ìŠ¤í… ìˆ˜ (ë†’ì„ìˆ˜ë¡ í’ˆì§ˆâ†‘, ì‹œê°„â†‘)
            guidance_scale: í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ ê°•ë„ (7-15 ê¶Œìž¥)
            strength: ë³€ê²½ ê°•ë„ (0.0-1.0, ë†’ì„ìˆ˜ë¡ ë§Žì´ ë³€ê²½)
        
        Returns:
            str: ì €ìž¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # 1. ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ì¤€ë¹„
        extended_image, mask = self.prepare_image_and_mask(image_path, extend_ratio)
        
        # 2. ì˜ìƒ íƒ€ìž… ê°ì§€
        clothing_type = self.detect_clothing_type(image_path)
        print(f"ðŸ‘• ê°ì§€ëœ ì˜ìƒ íƒ€ìž…: {clothing_type}")
        
        # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt, negative_prompt = self.get_prompt_for_clothing(
            clothing_type,
            Path(image_path).name
        )
        
        print(f"ðŸ“ Prompt: {prompt}")
        print(f"ðŸš« Negative: {negative_prompt}")
        
        # 4. Inpainting ìˆ˜í–‰
        print(f"ðŸŽ¨ ë³µì› ì¤‘... (Steps: {num_inference_steps})")
        
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=extended_image,
            mask_image=mask,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            strength=strength,
        ).images[0]
        
        # 5. ì €ìž¥
        if output_path is None:
            input_path = Path(image_path)
            output_path = input_path.parent / f"{input_path.stem}_restored.png"
        
        result.save(output_path)
        print(f"âœ… ì €ìž¥ ì™„ë£Œ: {output_path}")
        
        return str(output_path)
    
    def batch_restore(self, input_dir, output_dir=None, **kwargs):
        """
        í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë°°ì¹˜ ë³µì›
        
        Args:
            input_dir: ìž…ë ¥ í´ë”
            output_dir: ì¶œë ¥ í´ë” (Noneì´ë©´ ìž…ë ¥ í´ë”ì— ì €ìž¥)
            **kwargs: restore() í•¨ìˆ˜ì˜ ì¶”ê°€ ì¸ìž
        """
        input_path = Path(input_dir)
        
        if output_dir is None:
            output_path = input_path / "restored"
        else:
            output_path = Path(output_dir)
        
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_files = list(input_path.glob("*.png")) + \
                     list(input_path.glob("*.jpg")) + \
                     list(input_path.glob("*.jpeg"))
        
        print(f"ðŸ“ ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        
        for i, image_file in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] ì²˜ë¦¬ ì¤‘: {image_file.name}")
            
            output_file = output_path / f"{image_file.stem}_restored.png"
            
            try:
                self.restore(
                    str(image_file),
                    str(output_file),
                    **kwargs
                )
            except Exception as e:
                print(f"âŒ ì—ëŸ¬: {e}")
                continue
        
        print(f"\nðŸŽ‰ ì™„ë£Œ! ê²°ê³¼ í´ë”: {output_path}")


# ============================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("=" * 50)
    print("ðŸŽ¨ Clothing Restorer")
    print("=" * 50)
    
    # 1. Restorer ì´ˆê¸°í™”
    restorer = ClothingRestorer()
    
    # 2. ë‹¨ì¼ ì´ë¯¸ì§€ ë³µì›
    print("\në‹¨ì¼ ì´ë¯¸ì§€ ë³µì› ì‹œìž‘...")
    restorer.restore(
        image_path="/Users/grail/Documents/ClosetConnectProject/aiModel/í•˜ì˜_skirt_20251223_154654.png",
        output_path="restored_skirt.png",
        extend_ratio=0.5,          # 50% í™•ìž¥
        num_inference_steps=50,    # ìŠ¤í… ìˆ˜ (ë†’ì„ìˆ˜ë¡ í’ˆì§ˆâ†‘)
        guidance_scale=7.5,        # í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ ê°•ë„
        strength=0.8               # ë³€ê²½ ê°•ë„
    )
    
    print("\nâœ… ëª¨ë“  ìž‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()