"""
U2NET ë‹¨ì¼ ì˜· ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- huggingface-cloth-segmentationì˜ U2NET ëª¨ë¸ ì‚¬ìš©
- ë‹¨ì¼ ì˜· ì´ë¯¸ì§€ ì…ë ¥í•˜ì—¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í™•ì¸
"""

import sys
from pathlib import Path
from PIL import Image
import numpy as np
import torch

# huggingface-cloth-segmentation ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent / "huggingface-cloth-segmentation"))

try:
    from process import load_seg_model, get_palette, generate_mask
    print("âœ… U2NET ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    print(f"âŒ U2NET ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    sys.exit(1)


def test_u2net_segmentation(image_path, output_dir="test_outputs"):
    """
    U2NET ëª¨ë¸ë¡œ ë‹¨ì¼ ì˜· ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸

    Args:
        image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ U2NET ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸")
    print(f"{'='*60}\n")

    # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ“± ë””ë°”ì´ìŠ¤: {device}")

    # 2. ëª¨ë¸ ë¡œë“œ
    print("\nğŸ“¦ U2NET ëª¨ë¸ ë¡œë”© ì¤‘...")
    checkpoint_path = Path(__file__).parent.parent / "model" / "cloth_segm.pth"

    if not checkpoint_path.exists():
        print(f"âŒ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        print(f"   ë‹¤ìš´ë¡œë“œ í•„ìš”: https://github.com/wildoctopus/huggingface-cloth-segmentation")
        return

    try:
        model = load_seg_model(str(checkpoint_path), device=device)
        palette = get_palette(4)  # 4 classes
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 3. ì´ë¯¸ì§€ ë¡œë“œ
    print(f"\nğŸ“· ì´ë¯¸ì§€ ë¡œë“œ ì¤‘: {image_path}")
    image_path = Path(image_path)

    if not image_path.exists():
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    try:
        image = Image.open(image_path).convert("RGB")
        print(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {image.size} (WÃ—H)")
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 4. ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
    print(f"\nğŸ¯ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ ì¤‘...")
    try:
        cloth_mask = generate_mask(image, model, palette, device=device)
        print("âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 5. ê²°ê³¼ ë¶„ì„
    print(f"\nğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ë¶„ì„:")
    mask_np = np.array(cloth_mask)
    unique_labels = np.unique(mask_np)

    label_names = {
        0: "ë°°ê²½ (Background)",
        1: "ìƒì˜ (Upper body)",
        2: "í•˜ì˜ (Lower body)",
        3: "ì›í”¼ìŠ¤ (Full body)"
    }

    print(f"   ê°ì§€ëœ í´ë˜ìŠ¤:")
    for label_id in unique_labels:
        pixel_count = np.sum(mask_np == label_id)
        percentage = (pixel_count / mask_np.size) * 100
        label_name = label_names.get(label_id, f"Unknown ({label_id})")
        print(f"     - {label_name}: {pixel_count:,} pixels ({percentage:.2f}%)")

    # 6. ê²°ê³¼ ì €ì¥
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
    original_output = output_path / f"{image_path.stem}_original.png"
    image.save(original_output)
    print(f"\nğŸ’¾ ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥: {original_output}")

    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ì €ì¥
    mask_output = output_path / f"{image_path.stem}_mask.png"
    cloth_mask.save(mask_output)
    print(f"ğŸ’¾ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ì €ì¥: {mask_output}")

    # ê° í´ë˜ìŠ¤ë³„ ì•ŒíŒŒ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
    print(f"\nğŸ–¼ï¸  í´ë˜ìŠ¤ë³„ í¬ë¡­ ì´ë¯¸ì§€ ìƒì„±:")
    image_np = np.array(image)

    for label_id in unique_labels:
        if label_id == 0:  # ë°°ê²½ ì œì™¸
            continue

        # í•´ë‹¹ í´ë˜ìŠ¤ ë§ˆìŠ¤í¬
        class_mask = (mask_np == label_id).astype(np.uint8)
        pixel_count = np.sum(class_mask)

        if pixel_count < 1000:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
            print(f"   âš ï¸  {label_names.get(label_id, f'Label {label_id}')}: ì˜ì—­ì´ ë„ˆë¬´ ì‘ì•„ ê±´ë„ˆëœ€ ({pixel_count} pixels)")
            continue

        # Bounding box ê³„ì‚°
        rows = np.any(class_mask, axis=1)
        cols = np.any(class_mask, axis=0)

        if not rows.any() or not cols.any():
            continue

        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]

        # Adaptive padding (2% of bbox size)
        bbox_width = cmax - cmin
        bbox_height = rmax - rmin
        padding = max(5, min(20, int(max(bbox_width, bbox_height) * 0.02)))

        img_height, img_width = image_np.shape[:2]
        rmin_padded = max(0, rmin - padding)
        rmax_padded = min(img_height - 1, rmax + padding)
        cmin_padded = max(0, cmin - padding)
        cmax_padded = min(img_width - 1, cmax + padding)

        # í¬ë¡­
        mask_cropped = class_mask[rmin_padded:rmax_padded+1, cmin_padded:cmax_padded+1]
        image_cropped = image_np[rmin_padded:rmax_padded+1, cmin_padded:cmax_padded+1]

        # RGBA ì´ë¯¸ì§€ ìƒì„±
        alpha_channel = (mask_cropped * 255).astype(np.uint8)
        image_rgba = np.dstack([image_cropped, alpha_channel])

        # í’ˆì§ˆ í™•ì¸
        opaque_ratio = np.sum(alpha_channel > 0) / alpha_channel.size

        # ì €ì¥
        class_name = label_names.get(label_id, f"label_{label_id}").split(" (")[0]
        class_output = output_path / f"{image_path.stem}_{class_name}.png"
        Image.fromarray(image_rgba, mode='RGBA').save(class_output)

        status = "âœ…" if opaque_ratio > 0.6 else "âš ï¸"
        print(f"   {status} {label_names.get(label_id, f'Label {label_id}')}: {class_output.name}")
        print(f"       í¬ê¸°: {image_rgba.shape[1]}Ã—{image_rgba.shape[0]}, ë¶ˆíˆ¬ëª…ë„: {opaque_ratio*100:.1f}%")

    # 7. ë§ˆìŠ¤í¬ëœ ë¶€ë¶„ë§Œ ì›ë³¸ì—ì„œ ì¶”ì¶œ (ì „ì²´ ì´ë¯¸ì§€ í¬ê¸° ìœ ì§€, íˆ¬ëª… ë°°ê²½)
    print(f"\nğŸ¨ ë§ˆìŠ¤í¬ëœ ë¶€ë¶„ë§Œ ì›ë³¸ì—ì„œ ì¶”ì¶œ (ì „ì²´ í¬ê¸° ìœ ì§€):")

    for label_id in unique_labels:
        if label_id == 0:  # ë°°ê²½ ì œì™¸
            continue

        # í•´ë‹¹ í´ë˜ìŠ¤ ë§ˆìŠ¤í¬
        class_mask = (mask_np == label_id).astype(np.uint8)
        pixel_count = np.sum(class_mask)

        if pixel_count < 1000:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
            continue

        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ ë§ˆìŠ¤í¬ ì ìš©
        # RGB ì´ë¯¸ì§€ì™€ ì•ŒíŒŒ ì±„ë„(ë§ˆìŠ¤í¬) ê²°í•©
        alpha_channel_full = (class_mask * 255).astype(np.uint8)
        image_rgba_full = np.dstack([image_np, alpha_channel_full])

        # ì €ì¥
        class_name = label_names.get(label_id, f"label_{label_id}").split(" (")[0]
        full_output = output_path / f"{image_path.stem}_{class_name}_fullsize.png"
        Image.fromarray(image_rgba_full, mode='RGBA').save(full_output)

        print(f"   âœ… {label_names.get(label_id, f'Label {label_id}')}: {full_output.name}")
        print(f"       ì›ë³¸ í¬ê¸° ìœ ì§€: {image_rgba_full.shape[1]}Ã—{image_rgba_full.shape[0]}, ë§ˆìŠ¤í¬ ì˜ì—­: {pixel_count:,} pixels")

    # 8. ëª¨ë“  ì˜· í´ë˜ìŠ¤ í•©ì³ì„œ ì¶”ì¶œ (ë°°ê²½ë§Œ ì œê±°)
    print(f"\nğŸ‘” ëª¨ë“  ì˜· ì˜ì—­ í†µí•© ì¶”ì¶œ (ë°°ê²½ ì œê±°):")

    # ë°°ê²½ ì œì™¸í•œ ëª¨ë“  í´ë˜ìŠ¤ í•©ì¹˜ê¸°
    all_cloth_mask = (mask_np > 0).astype(np.uint8)  # label 0(ë°°ê²½) ì œì™¸
    cloth_pixel_count = np.sum(all_cloth_mask)

    if cloth_pixel_count > 0:
        # ì „ì²´ í¬ê¸° ë²„ì „ (ë°°ê²½ë§Œ íˆ¬ëª…)
        alpha_channel_all = (all_cloth_mask * 255).astype(np.uint8)
        image_rgba_all = np.dstack([image_np, alpha_channel_all])

        all_output = output_path / f"{image_path.stem}_all_clothes_fullsize.png"
        Image.fromarray(image_rgba_all, mode='RGBA').save(all_output)
        print(f"   âœ… ëª¨ë“  ì˜· ì˜ì—­: {all_output.name}")
        print(f"       ì›ë³¸ í¬ê¸° ìœ ì§€: {image_rgba_all.shape[1]}Ã—{image_rgba_all.shape[0]}")

        # íƒ€ì´íŠ¸ í¬ë¡­ ë²„ì „
        rows = np.any(all_cloth_mask, axis=1)
        cols = np.any(all_cloth_mask, axis=0)

        if rows.any() and cols.any():
            rmin, rmax = np.where(rows)[0][[0, -1]]
            cmin, cmax = np.where(cols)[0][[0, -1]]

            # Adaptive padding
            bbox_width = cmax - cmin
            bbox_height = rmax - rmin
            padding = max(5, min(20, int(max(bbox_width, bbox_height) * 0.02)))

            img_height, img_width = image_np.shape[:2]
            rmin_padded = max(0, rmin - padding)
            rmax_padded = min(img_height - 1, rmax + padding)
            cmin_padded = max(0, cmin - padding)
            cmax_padded = min(img_width - 1, cmax + padding)

            # í¬ë¡­
            mask_cropped_all = all_cloth_mask[rmin_padded:rmax_padded+1, cmin_padded:cmax_padded+1]
            image_cropped_all = image_np[rmin_padded:rmax_padded+1, cmin_padded:cmax_padded+1]

            # RGBA
            alpha_cropped_all = (mask_cropped_all * 255).astype(np.uint8)
            image_rgba_cropped_all = np.dstack([image_cropped_all, alpha_cropped_all])

            all_cropped_output = output_path / f"{image_path.stem}_all_clothes_cropped.png"
            Image.fromarray(image_rgba_cropped_all, mode='RGBA').save(all_cropped_output)
            print(f"   âœ… ëª¨ë“  ì˜· ì˜ì—­ (í¬ë¡­): {all_cropped_output.name}")
            print(f"       í¬ë¡­ í¬ê¸°: {image_rgba_cropped_all.shape[1]}Ã—{image_rgba_cropped_all.shape[0]}")

    print(f"\n{'='*60}")
    print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ëŠ” '{output_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="U2NET ë‹¨ì¼ ì˜· ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--image", type=str, required=True, help="ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--output", type=str, default="test_outputs", help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: test_outputs)")

    image="/Users/grail/Documents/ClosetConnectProject/aiModel/test/ìŠ¤í¬ë¦°ìƒ· 2023-12-19 18.18.54.png"
    output="/Users/grail/Documents/ClosetConnectProject/aiModel/test/"
    test_u2net_segmentation(image, output)
