"""
Segformer ë‹¤ì¤‘ ì˜ë¥˜ ê°ì§€ + í¬ë¡­ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ì´ë¯¸ì§€ì—ì„œ ê°ì§€ë˜ëŠ” ì˜ë¥˜ ì•„ì´í…œ ê°œìˆ˜ì™€ ì¢…ë¥˜ í™•ì¸
- ê° ì˜ë¥˜ ì•„ì´í…œì„ ì‹¤ì œë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜í•˜ê³  í¬ë¡­í•˜ì—¬ ì €ì¥
"""

import sys
from pathlib import Path
from PIL import Image
import numpy as np
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

try:
    from cloth_segmentation_api import ClothSegmentationModel
    print("âœ… ClothSegmentationModel import ì„±ê³µ")
except ImportError:
    print("âŒ ClothSegmentationModel import ì‹¤íŒ¨")
    print("   transformers ì‚¬ìš©ìœ¼ë¡œ ëŒ€ì²´")
    from transformers import AutoImageProcessor, AutoModelForSemanticSegmentation
    import torch

# ì˜ë¥˜ ë¼ë²¨ ì •ì˜ (Segformer 18 classes)
CLOTH_LABELS = {
    0: "background",
    1: "hat",
    2: "hair",
    3: "sunglasses",
    4: "upper-clothes",
    5: "skirt",
    6: "pants",
    7: "dress",
    8: "belt",
    9: "shoes",  # left-shoe + right-shoe í†µí•©
    10: "right-shoe",  # ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (9ë¡œ í†µí•©ë¨)
    11: "face",
    12: "left-leg",
    13: "right-leg",
    14: "left-arm",
    15: "right-arm",
    16: "bag",
    17: "scarf"
}

# ì˜ë¥˜ ì•„ì´í…œë§Œ (ì‹ ì²´ ë¶€ìœ„ ì œì™¸)
CLOTHING_ITEMS = {1, 4, 5, 6, 7, 8, 9, 16, 17}  # hat, upper-clothes, skirt, pants, dress, belt, shoes, bag, scarf


def extract_and_crop_item(image, pred_seg, label_id, label_name, output_dir):
    """
    íŠ¹ì • ë¼ë²¨ì˜ ì˜ë¥˜ ì•„ì´í…œì„ ì¶”ì¶œí•˜ê³  í¬ë¡­

    Args:
        image: ì›ë³¸ PIL Image (RGB)
        pred_seg: ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ (numpy array)
        label_id: ì¶”ì¶œí•  ë¼ë²¨ ID
        label_name: ë¼ë²¨ ì´ë¦„
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬

    Returns:
        cropped_image: í¬ë¡­ëœ PIL Image (RGBA)
    """
    # 1. í•´ë‹¹ ë¼ë²¨ì˜ ë§ˆìŠ¤í¬ ìƒì„±
    mask = (pred_seg == label_id).astype(np.uint8)

    # í”½ì…€ ìˆ˜ í™•ì¸
    pixel_count = np.sum(mask)
    if pixel_count == 0:
        print(f"  âš ï¸  {label_name}: í”½ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # 2. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ numpy arrayë¡œ ë³€í™˜
    image_np = np.array(image)

    # 3. ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
    rows = np.any(mask, axis=1)
    cols = np.any(mask, axis=0)
    y_min, y_max = np.where(rows)[0][[0, -1]]
    x_min, x_max = np.where(cols)[0][[0, -1]]

    # 4. íŒ¨ë”© ì¶”ê°€ (2% adaptive padding)
    height, width = mask.shape
    bbox_width = x_max - x_min
    bbox_height = y_max - y_min
    padding = max(5, min(20, int(0.02 * max(bbox_width, bbox_height))))

    y_min = max(0, y_min - padding)
    y_max = min(height, y_max + padding)
    x_min = max(0, x_min - padding)
    x_max = min(width, x_max + padding)

    # 5. í¬ë¡­ëœ ì˜ì—­ ì¶”ì¶œ
    cropped_image_np = image_np[y_min:y_max, x_min:x_max]
    cropped_mask = mask[y_min:y_max, x_min:x_max]

    # 6. ì•ŒíŒŒ ì±„ë„ ìƒì„± (ë§ˆìŠ¤í¬ë¥¼ ì•ŒíŒŒë¡œ ì‚¬ìš©)
    alpha_channel = (cropped_mask * 255).astype(np.uint8)

    # 7. RGBA ì´ë¯¸ì§€ ìƒì„±
    image_rgba = np.dstack([cropped_image_np, alpha_channel])
    result_image = Image.fromarray(image_rgba, mode='RGBA')

    # 8. ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{label_name}_{timestamp}.png"
    save_path = output_dir / filename
    result_image.save(save_path)

    print(f"  âœ… {label_name}: {result_image.size} â†’ {save_path.name}")

    return result_image


def test_segformer_detection(image_path):
    """
    Segformer ëª¨ë¸ë¡œ ì´ë¯¸ì§€ì—ì„œ ì˜ë¥˜ ì•„ì´í…œ ê°ì§€ í…ŒìŠ¤íŠ¸

    Args:
        image_path: í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
    """
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ Segformer ë‹¤ì¤‘ ì˜ë¥˜ ê°ì§€ í…ŒìŠ¤íŠ¸")
    print(f"{'='*70}\n")

    # 1. ì´ë¯¸ì§€ ë¡œë“œ
    print(f"ğŸ“· ì´ë¯¸ì§€ ë¡œë“œ ì¤‘: {image_path}")
    image_path = Path(image_path)

    if not image_path.exists():
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    try:
        image = Image.open(image_path).convert("RGB")
        print(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {image.size} (WÃ—H)\n")
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. ëª¨ë¸ ë¡œë“œ
    print("ğŸ“¦ Segformer ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        # ClothSegmentationModel ì‚¬ìš© ì‹œë„
        model = ClothSegmentationModel()
        print("âœ… ClothSegmentationModel ë¡œë“œ ì™„ë£Œ\n")
        use_custom_model = True
    except:
        # transformers ì§ì ‘ ì‚¬ìš©
        print("   ClothSegmentationModel ì‚¬ìš© ë¶ˆê°€, transformers ì§ì ‘ ì‚¬ìš©")
        model_name = "mattmdjaga/segformer_b2_clothes"
        processor = AutoImageProcessor.from_pretrained(model_name)
        model = AutoModelForSemanticSegmentation.from_pretrained(model_name)
        device = torch.device("cpu")
        model.to(device)
        model.eval()
        print("âœ… Transformers ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
        use_custom_model = False

    # 3. ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
    print("ğŸ¯ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ ì¤‘...")
    try:
        if use_custom_model:
            pred_seg = model.segment_image(image)
        else:
            # transformers ì§ì ‘ ì‚¬ìš©
            inputs = processor(images=image, return_tensors="pt")
            with torch.no_grad():
                outputs = model(**inputs)
            logits = outputs.logits
            pred_seg = torch.argmax(logits, dim=1).squeeze().cpu().numpy()

        print("âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3.5. ì‹ ë°œ í†µí•© (left-shoe + right-shoe â†’ shoes)
    left_shoe_exists = 9 in pred_seg
    right_shoe_exists = 10 in pred_seg

    if left_shoe_exists or right_shoe_exists:
        print(f"ğŸ‘Ÿ ì‹ ë°œ í†µí•©: left={left_shoe_exists}, right={right_shoe_exists}")
        pred_seg[pred_seg == 10] = 9  # right-shoeë¥¼ left-shoeë¡œ í†µí•©
        print(f"ğŸ‘Ÿ ì‹ ë°œ í†µí•© ì™„ë£Œ: left-shoe + right-shoe â†’ shoes\n")

    # 4. ê²°ê³¼ ë¶„ì„
    print(f"ğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ë¶„ì„:")
    print(f"{'='*70}\n")

    # ê°ì§€ëœ ëª¨ë“  í´ë˜ìŠ¤
    unique_labels = np.unique(pred_seg)
    print(f"ğŸ“‹ ê°ì§€ëœ ì „ì²´ í´ë˜ìŠ¤ ({len(unique_labels)}ê°œ):")
    print(f"{'-'*70}")

    all_items = []
    for label_id in unique_labels:
        pixel_count = np.sum(pred_seg == label_id)
        percentage = (pixel_count / pred_seg.size) * 100
        label_name = CLOTH_LABELS.get(label_id, f"Unknown ({label_id})")

        is_clothing = label_id in CLOTHING_ITEMS
        marker = "ğŸ‘”" if is_clothing else "  "

        all_items.append({
            'id': label_id,
            'name': label_name,
            'pixels': pixel_count,
            'percentage': percentage,
            'is_clothing': is_clothing
        })

        print(f"{marker} [{label_id:2d}] {label_name:20s}: {pixel_count:8,} pixels ({percentage:5.2f}%)")

    # ì˜ë¥˜ ì•„ì´í…œë§Œ í•„í„°ë§
    clothing_items = [item for item in all_items if item['is_clothing']]

    print(f"\n{'='*70}")
    print(f"ğŸ‘” ì˜ë¥˜ ì•„ì´í…œë§Œ ({len(clothing_items)}ê°œ):")
    print(f"{'-'*70}")

    if clothing_items:
        # í”½ì…€ ìˆ˜ë¡œ ì •ë ¬ (ë§ì€ ìˆœ)
        clothing_items_sorted = sorted(clothing_items, key=lambda x: x['pixels'], reverse=True)

        for item in clothing_items_sorted:
            print(f"   â€¢ {item['name']:20s}: {item['pixels']:8,} pixels ({item['percentage']:5.2f}%)")

        # ë©”ì¸ ì•„ì´í…œ (ê°€ì¥ í° ê²ƒ)
        main_item = clothing_items_sorted[0]
        print(f"\nğŸ¯ ë©”ì¸ ì•„ì´í…œ: {main_item['name']} ({main_item['pixels']:,} pixels, {main_item['percentage']:.2f}%)")

        if len(clothing_items_sorted) > 1:
            print(f"\nâœ¨ ì¶”ê°€ ì•„ì´í…œ ({len(clothing_items_sorted) - 1}ê°œ):")
            for item in clothing_items_sorted[1:]:
                print(f"   â€¢ {item['name']:20s}: {item['pixels']:8,} pixels ({item['percentage']:5.2f}%)")
    else:
        print("   âš ï¸  ì˜ë¥˜ ì•„ì´í…œì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    print(f"\n{'='*70}")
    print(f"âœ… ê°ì§€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"{'='*70}\n")

    return image, pred_seg, clothing_items


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
    image_path = "/Users/grail/Desktop/ìŠ¤í¬ë¦°ìƒ· 2025-12-27 11.09.25.png"

    print("\n" + "="*70)
    print("Segformer ë‹¤ì¤‘ ì˜ë¥˜ ê°ì§€ + í¬ë¡­ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*70)

    # 1. ê°ì§€ í…ŒìŠ¤íŠ¸
    result = test_segformer_detection(image_path)

    if result:
        image, pred_seg, clothing_items = result

        print(f"\nìµœì¢… ê²°ê³¼: {len(clothing_items)}ê°œì˜ ì˜ë¥˜ ì•„ì´í…œ ê°ì§€ë¨")
        print("\nê°ì§€ëœ ì•„ì´í…œ ëª©ë¡:")
        for i, item in enumerate(clothing_items, 1):
            print(f"  {i}. {item['name']}")

        # 2. ê° ì•„ì´í…œ í¬ë¡­ ë° ì €ì¥
        print(f"\n{'='*70}")
        print("ğŸ“¦ ê° ì•„ì´í…œ í¬ë¡­ ë° ì €ì¥ ì‹œì‘")
        print(f"{'='*70}\n")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path(__file__).parent / "test_output_segmented"
        output_dir.mkdir(exist_ok=True)
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}\n")

        cropped_results = []
        for item in clothing_items:
            label_id = item['id']
            label_name = item['name']
            print(f"ğŸ”§ {label_name} í¬ë¡­ ì¤‘...")

            cropped = extract_and_crop_item(
                image=image,
                pred_seg=pred_seg,
                label_id=label_id,
                label_name=label_name,
                output_dir=output_dir
            )

            if cropped:
                cropped_results.append({
                    'name': label_name,
                    'image': cropped,
                    'pixels': item['pixels']
                })

        print(f"\n{'='*70}")
        print(f"âœ… í¬ë¡­ ì™„ë£Œ! {len(cropped_results)}ê°œ ì•„ì´í…œ ì €ì¥ë¨")
        print(f"{'='*70}\n")

        print(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
        for item in cropped_results:
            print(f"  â€¢ {item['name']}: {item['image'].size} ({item['pixels']:,} pixels)")

        print(f"\nğŸ“‚ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    else:
        print("\nâŒ ê°ì§€ëœ ì˜ë¥˜ ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤.")
