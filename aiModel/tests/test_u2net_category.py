"""
U2NET ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path
from PIL import Image
import numpy as np

sys.path.append(str(Path(__file__).parent / "huggingface-cloth-segmentation"))

from process import load_seg_model, get_palette, generate_mask

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘
U2NET_LABEL_MAP = {
    0: "ë°°ê²½ (Background)",
    1: "ìƒì˜ (Upper body)",
    2: "í•˜ì˜ (Lower body)",
    3: "ì›í”¼ìŠ¤ (Full body)"
}

# Spring Boot Category enum ë§¤í•‘
CATEGORY_MAPPING = {
    1: "TOP",        # ìƒì˜ â†’ TOP
    2: "BOTTOM",     # í•˜ì˜ â†’ BOTTOM
    3: "TOP",        # ì›í”¼ìŠ¤ â†’ TOP (ì›í”¼ìŠ¤ë„ ìƒì˜ë¡œ ë¶„ë¥˜)
}

def detect_category(image_path):
    """U2NETìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€"""

    print(f"\n{'='*60}")
    print(f"ğŸ” U2NET ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€ í…ŒìŠ¤íŠ¸")
    print(f"{'='*60}\n")

    # ëª¨ë¸ ë¡œë“œ
    checkpoint_path = Path(__file__).parent.parent / "model" / "cloth_segm.pth"
    model = load_seg_model(str(checkpoint_path), device="cpu")
    palette = get_palette(4)

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path).convert("RGB")
    print(f"ğŸ“· ì´ë¯¸ì§€: {image_path}")
    print(f"   í¬ê¸°: {image.size} (WÃ—H)\n")

    # ì„¸ê·¸ë©˜í…Œì´ì…˜
    cloth_mask = generate_mask(image, model, palette, device="cpu")
    mask_np = np.array(cloth_mask)

    # ê° í´ë˜ìŠ¤ë³„ í”½ì…€ ìˆ˜ ë¶„ì„
    print("ğŸ“Š ê°ì§€ëœ í´ë˜ìŠ¤ ë¶„ì„:")
    unique_labels = np.unique(mask_np)

    class_pixels = {}
    for label_id in unique_labels:
        pixel_count = np.sum(mask_np == label_id)
        percentage = (pixel_count / mask_np.size) * 100
        class_pixels[label_id] = pixel_count

        label_name = U2NET_LABEL_MAP.get(label_id, f"Unknown ({label_id})")
        print(f"   {label_name}: {pixel_count:,} pixels ({percentage:.2f}%)")

    # ë°°ê²½ ì œì™¸í•˜ê³  ê°€ì¥ ë§ì€ í”½ì…€ì„ ì°¨ì§€í•˜ëŠ” í´ë˜ìŠ¤ ì°¾ê¸°
    cloth_pixels = {k: v for k, v in class_pixels.items() if k != 0}

    if not cloth_pixels:
        print("\nâŒ ì˜· ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return None

    # ê°€ì¥ ë§ì€ í”½ì…€ì„ ê°€ì§„ í´ë˜ìŠ¤
    dominant_class = max(cloth_pixels, key=cloth_pixels.get)
    dominant_label = U2NET_LABEL_MAP.get(dominant_class)
    dominant_pixels = cloth_pixels[dominant_class]
    dominant_percentage = (dominant_pixels / mask_np.size) * 100

    # Spring Boot ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    spring_category = CATEGORY_MAPPING.get(dominant_class, "TOP")

    print(f"\nğŸ¯ ìë™ ê°ì§€ ê²°ê³¼:")
    print(f"   ì§€ë°°ì  í´ë˜ìŠ¤: {dominant_label}")
    print(f"   í”½ì…€ ìˆ˜: {dominant_pixels:,} ({dominant_percentage:.2f}%)")
    print(f"   â†’ Spring Category: {spring_category}")

    return {
        "u2net_class_id": dominant_class,
        "u2net_label": dominant_label,
        "spring_category": spring_category,
        "pixel_count": dominant_pixels,
        "percentage": dominant_percentage,
        "all_detected": cloth_pixels
    }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤
    test_images = [
        "/Users/grail/Documents/ClosetConnectProject/aiModel/huggingface-cloth-segmentation/input/03615_00.jpg",
        "/Users/grail/Documents/ClosetConnectProject/aiModel/test/ìŠ¤í¬ë¦°ìƒ· 2023-12-19 18.18.54.png",
    ]

    for img_path in test_images:
        if Path(img_path).exists():
            result = detect_category(img_path)
            print(f"\n{'='*60}\n")
